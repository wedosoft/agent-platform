# FastAPI가 Node 기반 파이프라인을 프록시할 기본 엔드포인트
AGENT_PLATFORM_PIPELINE_BASE_URL=http://localhost:4000/pipeline

# 공통 문서 Supabase 프로젝트 설정
# (실제 환경 값으로 교체)
AGENT_PLATFORM_SUPABASE_COMMON_URL=https://project.supabase.co
AGENT_PLATFORM_SUPABASE_COMMON_SERVICE_ROLE_KEY=service-role-key
AGENT_PLATFORM_SUPABASE_COMMON_TABLE_NAME=documents
AGENT_PLATFORM_SUPABASE_COMMON_DEFAULT_PRODUCT=
AGENT_PLATFORM_SUPABASE_COMMON_BATCH_SIZE=50
AGENT_PLATFORM_SUPABASE_COMMON_LANGUAGES=ko,en

# Gemini 설정
GEMINI_API_KEY=
AGENT_PLATFORM_GEMINI_PRIMARY_MODEL=gemini-2.5-flash
AGENT_PLATFORM_GEMINI_FALLBACK_MODEL=gemini-2.0-flash
AGENT_PLATFORM_GEMINI_COMMON_STORE_NAME=

# Freshdesk API 설정
AGENT_PLATFORM_FRESHDESK_DOMAIN=
AGENT_PLATFORM_FRESHDESK_API_KEY=

# Fly.io Redis 애드온 사용 시 주석 해제하고 실제 URL로 교체하세요
# AGENT_PLATFORM_REDIS_URL=redis://default:password@redis-host:port/0

# -----------------------------------------------------------------------------
# Local LLM (OpenAI-compatible) routing (PR3)
# -----------------------------------------------------------------------------
# 아래 키들은 `app/core/config.py`의 Settings 필드명과 동일합니다.
# 예) Ollama OpenAI-compatible:
#   LLM_LOCAL_ENABLED=true
#   LLM_LOCAL_BASE_URL=http://127.0.0.1:11434/v1
#   LLM_LOCAL_MODEL=llama3.2:3b
#   LLM_LOCAL_API_KEY=optional
LLM_LOCAL_ENABLED=false
LLM_LOCAL_BASE_URL=
LLM_LOCAL_API_KEY=
LLM_LOCAL_MODEL=
# Comma-separated purposes (default: propose_fields_only)
LLM_LOCAL_PURPOSES=propose_fields_only
# Timeouts (ms)
LLM_LOCAL_TIMEOUT_MS=1200
LLM_CLOUD_TIMEOUT_MS_FIELDS_ONLY=8000
