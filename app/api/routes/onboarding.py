"""ì˜¨ë³´ë”© ì „ìš© API ë¼ìš°í„°."""

import json
import logging
from typing import List, Optional

from fastapi import APIRouter, HTTPException, Query, UploadFile, File, Form
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

from app.services.gemini_client import get_gemini_client
from app.services.gemini_file_search import upload_document_to_store, get_store_documents
from app.services.onboarding_repository import get_onboarding_repository
from app.services.supabase_kb_client import get_kb_client
from app.core.config import get_settings

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/onboarding", tags=["onboarding"])

settings = get_settings()

# ì˜¨ë³´ë”©ì—ì„œ ì‚¬ìš©í•  RAG ìŠ¤í† ì–´ë“¤
STORE_PRODUCT = settings.gemini_store_common      # ì œí’ˆ ì§€ì‹ (Freshworks, Google ë“±)
STORE_HANDOVER = settings.gemini_store_onboarding  # ì¸ìˆ˜ì¸ê³„/í”„ë¡œì„¸ìŠ¤ ë¬¸ì„œ


# ============================================
# Request/Response Models
# ============================================

class CreateSessionRequest(BaseModel):
    """ì„¸ì…˜ ìƒì„± ìš”ì²­."""
    userName: str


class CreateSessionResponse(BaseModel):
    """ì„¸ì…˜ ìƒì„± ì‘ë‹µ."""
    sessionId: str
    message: str


class SaveProgressRequest(BaseModel):
    """ì§„í–‰ë„ ì €ì¥ ìš”ì²­."""
    sessionId: str
    scenarioId: str
    choiceId: str
    feedbackRating: Optional[int] = None


# ============================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# ============================================

MENTOR_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ìµœìƒìœ„ í…Œí¬ ê¸°ì—…ì˜ ì‹œë‹ˆì–´ ë©˜í†  'ì˜¨ë³´ë”© ë‚˜ì¹¨ë°˜'ì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ íŠ¹ì§•:
- ê°„ê²°í•˜ê³  ë³¸ë¡  ì¤‘ì‹¬ì˜ ë‹µë³€ (ì¸ì‚¬ë§ì´ë‚˜ ì´ë¦„ ì–¸ê¸‰ ì—†ì´ ë°”ë¡œ í•µì‹¬ìœ¼ë¡œ)
- ì‹¤ì§ˆì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸
- ìƒì‚°ì„±, ì‹œê°„ ê´€ë¦¬, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ë¬¸ì œ í•´ê²°, í˜‘ì—…ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹
- í•œêµ­ì–´ë¡œ ë‹µë³€

ì§ˆë¬¸ì— ëŒ€í•´ ë°”ë¡œ ë³¸ë¡ ìœ¼ë¡œ ë“¤ì–´ê°€ì„œ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”. ì´ë¦„ì„ ë¶€ë¥´ê±°ë‚˜ ì¸ì‚¬ë§ì„ í•˜ì§€ ë§ˆì„¸ìš”."""


def get_feedback_prompt(
    user_name: str,
    scenario_title: str,
    scenario_description: str,
    all_choices: List[str],
    selected_choice: str
) -> str:
    """ì‹œë‚˜ë¦¬ì˜¤ í”¼ë“œë°± ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸."""
    all_choices_text = '\n'.join(f'- {choice}' for choice in all_choices)
    
    return f"""ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ìµœìƒìœ„ í…Œí¬ ê¸°ì—…ì˜ ë…¸ë ¨í•œ ì‹œë‹ˆì–´ ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.

ì—…ë¬´ ì‹œë‚˜ë¦¬ì˜¤:
**ì œëª©:** {scenario_title}
**ìƒí™©:** {scenario_description}

ì„ íƒ ê°€ëŠ¥í•œ í–‰ë™ë“¤:
{all_choices_text}

**ì„ íƒí•œ í–‰ë™:** "{selected_choice}"

ì´ ì„ íƒì— ëŒ€í•´ ëª…í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°±ì„ ì œê³µí•´ ì£¼ì„¸ìš”.
**ì¤‘ìš”: ì´ë¦„ì„ ë¶€ë¥´ê±°ë‚˜ ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ë³¸ë¡ ìœ¼ë¡œ ë“¤ì–´ê°€ì„¸ìš”.**
**í”¼ë“œë°±ì€ ë°˜ë“œì‹œ ì•„ë˜ì˜ ë§ˆí¬ë‹¤ìš´ ì„œì‹ì„ ì •í™•íˆ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.**

### ğŸ¤· ì„ íƒì— ëŒ€í•œ ë¶„ì„
(ì„ íƒì„ ì¸ì •í•˜ê³ , ì‹¤ì œ ì—…ë¬´ í™˜ê²½ì—ì„œ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì¥ì ê³¼ ë‹¨ì ì„ ê· í˜• ìˆê²Œ ë¶„ì„)

---

### ğŸ’¡ ì¶”ì²œí•˜ëŠ” ì ‘ê·¼ ë°©ì‹
(ì´ ì‹œë‚˜ë¦¬ì˜¤ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ê°€ì¥ íš¨ê³¼ì ì¸ ì—…ë¬´ ì›ì¹™ì´ë‚˜ ì‚¬ê³  ëª¨ë¸ ì„¤ëª…. ê°€ì¥ ì´ìƒì ì¸ í–‰ë™ê³¼ ê·¸ ì´ìœ ë¥¼ ëª…í™•íˆ ì œì‹œ)

---

### ğŸ¤” ë‹¤ë¥¸ ì„ íƒì§€ë“¤ì— ëŒ€í•œ ê³ ì°°
(ì„ íƒë˜ì§€ ì•Šì€ ë‹¤ë¥¸ ì˜µì…˜ë“¤ì´ ì™œ ëœ íš¨ê³¼ì ì¸ì§€ ê°„ëµí•˜ê²Œ ì„¤ëª…)

---

### â­ í•µì‹¬ ì •ë¦¬
> (ì•ìœ¼ë¡œ ìœ ì‚¬í•œ ìƒí™©ì—ì„œ ê¸°ì–µí•˜ê³  ì ìš©í•  ìˆ˜ ìˆëŠ” í•µì‹¬ ì›ì¹™ì´ë‚˜ êµí›ˆì„ blockquote í˜•ì‹ìœ¼ë¡œ ì‘ì„±)

**í”¼ë“œë°± ì‘ì„±ì´ ëë‚˜ë©´, ë°˜ë“œì‹œ ë‹¤ìŒ ì¤„ì— %%%QUESTIONS%%% ë¼ëŠ” êµ¬ë¶„ìë¥¼ ì‚½ì…í•´ì£¼ì„¸ìš”.**

ê·¸ ë‹¤ìŒ ì¤„ë¶€í„°, ì´ ì£¼ì œì— ëŒ€í•´ ë” ê¹Šì´ ìƒê°í•´ë³¼ ìˆ˜ ìˆëŠ” 3ê°œì˜ ì—°ê´€ ì§ˆë¬¸ì„ ê°ê° í•œ ì¤„ì”© ì‘ì„±í•´ì£¼ì„¸ìš”. ì§ˆë¬¸ ì•ì—ëŠ” ë²ˆí˜¸ë‚˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¥¼ ë¶™ì´ì§€ ë§ˆì„¸ìš”."""


def get_followup_prompt(
    user_name: str,
    scenario_title: str,
    scenario_description: str,
    original_feedback: str,
    question: str
) -> str:
    """í›„ì† ì§ˆë¬¸ ë‹µë³€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸."""
    return f"""ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ìµœìƒìœ„ í…Œí¬ ê¸°ì—…ì˜ ì‹œë‹ˆì–´ ë©˜í† ì…ë‹ˆë‹¤.

**ìƒí™©:**
- **ì‹œë‚˜ë¦¬ì˜¤:** {scenario_title} ({scenario_description})
- **ì´ì „ ì¡°ì–¸ ìš”ì•½:** {original_feedback[:500]}...

**ì¶”ê°€ ì§ˆë¬¸:** "{question}"

ì´ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³ , ì‹¤ì§ˆì ì´ë©°, ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
**ì¤‘ìš”: ì´ë¦„ì„ ë¶€ë¥´ê±°ë‚˜ ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ë³¸ë¡ ìœ¼ë¡œ ë“¤ì–´ê°€ì„¸ìš”.**
ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ, í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”."""


# ============================================
# SSE í—¬í¼
# ============================================

def format_sse(event: str, data: dict) -> str:
    """SSE í¬ë§·ìœ¼ë¡œ ë³€í™˜."""
    return f"event: {event}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"


# ============================================
# ì„¸ì…˜ ê´€ë¦¬ (Supabase ì˜ì†í™”, í´ë°±: ì¸ë©”ëª¨ë¦¬)
# ============================================

# ëŒ€í™” íˆìŠ¤í† ë¦¬ìš© ì¸ë©”ëª¨ë¦¬ ìºì‹œ (ì„¸ì…˜ ë©”íƒ€ë°ì´í„°ëŠ” Supabaseì— ì €ì¥)
_conversation_cache: dict = {}


@router.post("/session", response_model=CreateSessionResponse)
async def create_session(request: CreateSessionRequest):
    """ì˜¨ë³´ë”© ì„¸ì…˜ ìƒì„±."""
    import uuid
    session_id = f"onboarding-{uuid.uuid4().hex[:8]}"

    # Supabaseì— ì„¸ì…˜ ì €ì¥ (ë˜ëŠ” ì¸ë©”ëª¨ë¦¬ í´ë°±)
    repo = get_onboarding_repository()
    await repo.create_session(session_id, request.userName)

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìºì‹œ ì´ˆê¸°í™”
    _conversation_cache[session_id] = {
        "userName": request.userName,
        "conversationHistory": [],
    }

    logger.info(f"Created onboarding session: {session_id} for user: {request.userName}")

    return CreateSessionResponse(
        sessionId=session_id,
        message="ì˜¨ë³´ë”© ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
    )


# ============================================
# ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° (AI ë©˜í† )
# ============================================

@router.get("/chat/stream")
async def chat_stream(
    sessionId: str = Query(...),
    query: str = Query(...),
):
    """AI ë©˜í†  ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° (RAG ê²€ìƒ‰ í¬í•¨)."""

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìºì‹œì—ì„œ ì¡°íšŒ, ì—†ìœ¼ë©´ Supabaseì—ì„œ ì„¸ì…˜ ì •ë³´ ì¡°íšŒ
    session = _conversation_cache.get(sessionId)
    if not session:
        repo = get_onboarding_repository()
        db_session = await repo.get_session(sessionId)
        user_name = db_session.user_name if db_session else "ì‹ ì…ì‚¬ì›"
        session = {"userName": user_name, "conversationHistory": []}
        _conversation_cache[sessionId] = session

    user_name = session.get("userName", "ì‹ ì…ì‚¬ì›")
    history = session.get("conversationHistory", [])
    
    # ì‚¬ìš©í•  RAG ìŠ¤í† ì–´ ëª©ë¡
    rag_stores = []
    if STORE_PRODUCT:
        rag_stores.append(STORE_PRODUCT)
    if STORE_HANDOVER:
        rag_stores.append(STORE_HANDOVER)
    
    async def event_generator():
        try:
            client = get_gemini_client()
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
            messages = [
                {"role": "user", "parts": [{"text": MENTOR_SYSTEM_PROMPT}]},
                {"role": "model", "parts": [{"text": "ë„¤, ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."}]},
            ]
            
            # íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 4í„´)
            for turn in history[-4:]:
                messages.append({"role": "user", "parts": [{"text": turn.get("user", "")}]})
                messages.append({"role": "model", "parts": [{"text": turn.get("model", "")}]})
            
            # í˜„ì¬ ì§ˆë¬¸
            messages.append({"role": "user", "parts": [{"text": query}]})
            
            # RAG ê²€ìƒ‰ ì„¤ì • (ì—¬ëŸ¬ ìŠ¤í† ì–´ ë™ì‹œ ê²€ìƒ‰)
            from google.genai import types

            # ìŠ¤í† ì–´ê°€ ìˆìœ¼ë©´ íŒŒì¼ ê²€ìƒ‰ ë„êµ¬ ì¶”ê°€
            tools = None
            if rag_stores:
                tools = [
                    types.Tool(
                        file_search=types.FileSearch(
                            file_search_store_names=rag_stores
                        )
                    )
                ]

            generation_config = types.GenerateContentConfig(
                thinking_config=types.ThinkingConfig(thinking_budget=0),
                tools=tools,
            )

            full_response = ""

            # ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
            model_name = client.models[0]
            response = client.client.models.generate_content_stream(
                model=model_name,
                contents=messages,
                config=generation_config,
            )
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    yield format_sse("chunk", {"text": chunk.text})
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            history.append({"user": query, "model": full_response})
            session["conversationHistory"] = history[-10:]  # ìµœê·¼ 10í„´ë§Œ ìœ ì§€
            
            yield format_sse("result", {"text": full_response})
            
        except Exception as e:
            logger.error(f"Chat stream error: {e}")
            yield format_sse("error", {"message": str(e)})
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )


# ============================================
# ì‹œë‚˜ë¦¬ì˜¤ í”¼ë“œë°± ìŠ¤íŠ¸ë¦¬ë°
# ============================================

@router.get("/feedback/stream")
async def feedback_stream(
    sessionId: str = Query(...),
    scenarioId: str = Query(...),
    scenarioTitle: str = Query(...),
    scenarioDescription: str = Query(...),
    selectedChoice: str = Query(...),
    userName: str = Query(...),
    allChoices: List[str] = Query(...),
):
    """ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒì— ëŒ€í•œ í”¼ë“œë°± ìŠ¤íŠ¸ë¦¬ë°."""
    
    async def event_generator():
        try:
            client = get_gemini_client()
            
            prompt = get_feedback_prompt(
                user_name=userName,
                scenario_title=scenarioTitle,
                scenario_description=scenarioDescription,
                all_choices=allChoices,
                selected_choice=selectedChoice,
            )
            
            full_response = ""
            feedback_text = ""
            questions_buffer = ""
            separator_found = False
            separator = "%%%QUESTIONS%%%"
            
            async for chunk in client.generate_content_stream(
                contents=prompt,
                config={"thinking_config": {"thinking_budget": 0}}
            ):
                if chunk.text:
                    chunk_text = chunk.text
                    full_response += chunk_text
                    
                    if separator_found:
                        questions_buffer += chunk_text
                    else:
                        if separator in chunk_text:
                            separator_found = True
                            parts = chunk_text.split(separator)
                            feedback_text += parts[0]
                            if len(parts) > 1:
                                questions_buffer += parts[1]
                            yield format_sse("feedback_chunk", {"text": parts[0]})
                        else:
                            feedback_text += chunk_text
                            yield format_sse("feedback_chunk", {"text": chunk_text})
            
            # í›„ì† ì§ˆë¬¸ íŒŒì‹±
            questions = []
            if questions_buffer:
                questions = [q.strip() for q in questions_buffer.strip().split('\n') if q.strip()]
            
            yield format_sse("questions", {"questions": questions})
            yield format_sse("result", {"text": feedback_text, "questions": questions})
            
        except Exception as e:
            logger.error(f"Feedback stream error: {e}")
            yield format_sse("error", {"message": str(e)})
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )


# ============================================
# í›„ì† ì§ˆë¬¸ ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
# ============================================

@router.get("/followup/stream")
async def followup_stream(
    sessionId: str = Query(...),
    scenarioId: str = Query(...),
    scenarioTitle: str = Query(...),
    scenarioDescription: str = Query(...),
    originalFeedback: str = Query(...),
    question: str = Query(...),
    userName: str = Query(...),
):
    """í›„ì† ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°."""
    
    async def event_generator():
        try:
            client = get_gemini_client()
            
            prompt = get_followup_prompt(
                user_name=userName,
                scenario_title=scenarioTitle,
                scenario_description=scenarioDescription,
                original_feedback=originalFeedback,
                question=question,
            )
            
            full_response = ""
            
            async for chunk in client.generate_content_stream(
                contents=prompt,
                config={"thinking_config": {"thinking_budget": 0}}
            ):
                if chunk.text:
                    full_response += chunk.text
                    yield format_sse("chunk", {"text": chunk.text})
            
            yield format_sse("result", {"text": full_response})
            
        except Exception as e:
            logger.error(f"Follow-up stream error: {e}")
            yield format_sse("error", {"message": str(e)})
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )


# ============================================
# ì§„í–‰ë„ ê´€ë¦¬ (Supabase ì˜ì†í™”)
# ============================================

@router.post("/progress")
async def save_progress(request: SaveProgressRequest):
    """ì‹œë‚˜ë¦¬ì˜¤ ì™„ë£Œ ì§„í–‰ë„ ì €ì¥ (Supabaseì— ì˜ì†í™”)."""
    repo = get_onboarding_repository()

    try:
        await repo.save_progress(
            session_id=request.sessionId,
            scenario_id=request.scenarioId,
            choice_id=request.choiceId,
            feedback_rating=request.feedbackRating,
        )
        logger.info(f"Saved progress for session {request.sessionId}: scenario {request.scenarioId}")
        return {"success": True}
    except Exception as e:
        logger.error(f"Failed to save progress: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/progress/{sessionId}")
async def get_progress(sessionId: str):
    """ì§„í–‰ë„ ì¡°íšŒ (Supabaseì—ì„œ ì¡°íšŒ)."""
    repo = get_onboarding_repository()

    try:
        summary = await repo.get_progress_summary(sessionId, total_scenarios=12)
        return {
            "userId": summary.user_id,
            "userName": summary.user_name,
            "completedScenarios": [
                {
                    "scenarioId": p.scenario_id,
                    "choiceId": p.choice_id,
                    "feedbackRating": p.feedback_rating,
                    "completedAt": p.completed_at.isoformat() if p.completed_at else None,
                }
                for p in summary.completed_scenarios
            ],
            "totalScenarios": summary.total_scenarios,
            "completionRate": summary.completion_rate,
        }
    except Exception as e:
        logger.error(f"Failed to get progress: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/progress")
async def get_all_progress():
    """ëª¨ë“  ì„¸ì…˜ì˜ ì§„í–‰ë„ ìš”ì•½ ì¡°íšŒ (ê´€ë¦¬ììš©)."""
    repo = get_onboarding_repository()

    try:
        summaries = await repo.get_all_sessions_summary()
        return {"sessions": summaries}
    except Exception as e:
        logger.error(f"Failed to get all progress: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ë¬¸ì„œ ì—…ë¡œë“œ (ì¸ìˆ˜ì¸ê³„/í”„ë¡œì„¸ìŠ¤ ë¬¸ì„œ)
# ============================================

@router.post("/documents")
async def upload_onboarding_document(
    file: UploadFile = File(...),
    metadata: Optional[str] = Form(None),
):
    """ì˜¨ë³´ë”©/ì¸ìˆ˜ì¸ê³„ ë¬¸ì„œ ì—…ë¡œë“œ."""
    if not STORE_HANDOVER:
        raise HTTPException(
            status_code=500,
            detail="Onboarding store not configured"
        )
    
    try:
        parsed_metadata = []
        if metadata:
            parsed_metadata = json.loads(metadata)
        
        file_content = await file.read()
        result = await upload_document_to_store(
            store_name=STORE_HANDOVER,
            file_name=file.filename or "document.txt",
            file_content=file_content,
            metadata=parsed_metadata,
        )
        
        logger.info(f"Uploaded document: {result.get('displayName')}")
        return result
        
    except Exception as e:
        logger.error(f"Document upload failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/documents")
async def list_onboarding_documents(
    category: Optional[str] = None,
):
    """ì—…ë¡œë“œëœ ì˜¨ë³´ë”© ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ."""
    if not STORE_HANDOVER:
        raise HTTPException(
            status_code=500,
            detail="Onboarding store not configured"
        )
    
    try:
        result = await get_store_documents(STORE_HANDOVER)
        documents = result.get("documents", [])
        
        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        if category:
            documents = [
                doc for doc in documents
                if any(
                    m.get("key") == "category" and m.get("stringValue") == category
                    for m in (doc.get("customMetadata") or [])
                )
            ]
        
        return documents
        
    except Exception as e:
        logger.error(f"Document list failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/documents/{document_name:path}")
async def delete_onboarding_document(document_name: str):
    """ì˜¨ë³´ë”© ë¬¸ì„œ ì‚­ì œ."""
    from app.services.gemini_file_search import delete_document

    try:
        await delete_document(document_name)
        logger.info(f"Deleted document: {document_name}")
        return {"success": True, "deleted": document_name}

    except Exception as e:
        logger.error(f"Document delete failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ì§€ì‹ ë² ì´ìŠ¤ (Knowledge Base)
# ============================================

class StructureKnowledgeRequest(BaseModel):
    """ì§€ì‹ êµ¬ì¡°í™” ìš”ì²­."""
    rawContent: str
    category: str


class CreateKnowledgeArticleRequest(BaseModel):
    """ì§€ì‹ ì•„í‹°í´ ìƒì„± ìš”ì²­."""
    title: str
    author: str
    category: str
    rawContent: str
    structuredSummary: str


class KnowledgeArticleResponse(BaseModel):
    """ì§€ì‹ ì•„í‹°í´ ì‘ë‹µ."""
    id: str
    title: str
    author: str
    category: str
    rawContent: str
    structuredSummary: Optional[str] = None
    createdAt: str


# ì¸ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” Supabase ì‚¬ìš©)
_knowledge_store: list = []


def get_structure_prompt(category: str) -> str:
    """ë²”ì£¼ë³„ êµ¬ì¡°í™” í”„ë¡¬í”„íŠ¸ ìƒì„±."""
    category_prompts = {
        "handover": """
ë‹¤ìŒ ì¸ìˆ˜ì¸ê³„ ë‚´ìš©ì„ êµ¬ì¡°í™”í•˜ì„¸ìš”:
1. **í•µì‹¬ ì§„í–‰ ì‚¬í•­**: í˜„ì¬ ì§„í–‰ ì¤‘ì¸ í”„ë¡œì íŠ¸/ì—…ë¬´
2. **ì£¼ìš” ì—°ë½ì²˜**: ì—°ë½í•´ì•¼ í•  ì‚¬ëŒê³¼ ì´ìœ 
3. **íŒŒì¼/ì ‘ê·¼ ì •ë³´**: íŒŒì¼ ìœ„ì¹˜, ê³„ì • ì •ë³´ ë“±
4. **ì£¼ì˜ì‚¬í•­/ì •ì±…**: ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ì‚¬í•­
5. **ì•¡ì…˜ ì•„ì´í…œ**: ì¦‰ì‹œ í•´ì•¼ í•  ì¼
""",
        "process": """
ë‹¤ìŒ ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬ì¡°í™”í•˜ì„¸ìš”:
1. **ê°œìš”**: ì—…ë¬´ ëª©ì ê³¼ ë°°ê²½
2. **ë‹¨ê³„ë³„ ì ˆì°¨**: ìˆœì„œëŒ€ë¡œ ì •ë¦¬
3. **ì£¼ì˜ì‚¬í•­**: ì‹¤ìˆ˜í•˜ê¸° ì‰¬ìš´ ë¶€ë¶„
4. **ê´€ë ¨ ì‹œìŠ¤í…œ/ë„êµ¬**: ì‚¬ìš©í•˜ëŠ” ë„êµ¬
5. **ë‹´ë‹¹ì/ë¬¸ì˜ì²˜**: ë„ì›€ ë°›ì„ ìˆ˜ ìˆëŠ” ê³³
""",
        "tips": """
ë‹¤ìŒ íŒ/ë…¸í•˜ìš°ë¥¼ êµ¬ì¡°í™”í•˜ì„¸ìš”:
1. **í•µì‹¬ í¬ì¸íŠ¸**: ê°€ì¥ ì¤‘ìš”í•œ ë‚´ìš©
2. **ì ìš© ë°©ë²•**: ì‹¤ì œ ì ìš©í•˜ëŠ” ë°©ë²•
3. **ì£¼ì˜ì **: ì˜ëª» ì ìš©í•˜ë©´ ì•ˆë˜ëŠ” ê²½ìš°
4. **ê´€ë ¨ íŒ**: í•¨ê»˜ ì•Œë©´ ì¢‹ì€ ë‚´ìš©
""",
        "company": """
ë‹¤ìŒ íšŒì‚¬ ìƒí™œ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ì„¸ìš”:
1. **ìš”ì•½**: í•µì‹¬ ë‚´ìš©
2. **ìƒì„¸ ì •ë³´**: ì•Œì•„ì•¼ í•  ì„¸ë¶€ì‚¬í•­
3. **ìœ ìš©í•œ íŒ**: í™œìš©í•˜ë©´ ì¢‹ì€ ì 
4. **ê´€ë ¨ ì •ë³´**: í•¨ê»˜ ì•Œë©´ ì¢‹ì€ ë‚´ìš©
""",
        "tools": """
ë‹¤ìŒ ì‹œìŠ¤í…œ/ë„êµ¬ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ì„¸ìš”:
1. **ê°œìš”**: ë„êµ¬ì˜ ìš©ë„
2. **ì ‘ê·¼ ë°©ë²•**: ì–´ë–»ê²Œ ì ‘ê·¼í•˜ëŠ”ì§€
3. **ì£¼ìš” ê¸°ëŠ¥**: ìì£¼ ì‚¬ìš©í•˜ëŠ” ê¸°ëŠ¥
4. **íŒ**: íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•
5. **ë¬¸ì œ í•´ê²°**: ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²°ë²•
""",
    }
    return category_prompts.get(category, """
ë‹¤ìŒ ë‚´ìš©ì„ êµ¬ì¡°í™”í•˜ì„¸ìš”:
1. **í•µì‹¬ ë‚´ìš©**: ê°€ì¥ ì¤‘ìš”í•œ í¬ì¸íŠ¸
2. **ìƒì„¸ ì •ë³´**: ì„¸ë¶€ ì‚¬í•­
3. **ê´€ë ¨ ì •ë³´**: ì°¸ê³ í•  ë‚´ìš©
""")


@router.post("/knowledge/structure")
async def structure_knowledge_content(request: StructureKnowledgeRequest):
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ì‹ ì½˜í…ì¸  êµ¬ì¡°í™”."""
    try:
        client = get_gemini_client()

        structure_guide = get_structure_prompt(request.category)
        prompt = f"""ë‹¹ì‹ ì€ ì‚¬ë‚´ ì§€ì‹ì„ ì •ë¦¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

{structure_guide}

ì›ë³¸ ë‚´ìš©:
"{request.rawContent}"

ìœ„ ë‚´ìš©ì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”í•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

        response = await client.generate_content(
            contents=prompt,
            config={"thinking_config": {"thinking_budget": 0}}
        )

        return {"structuredSummary": response.text}

    except Exception as e:
        logger.error(f"Knowledge structure failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/knowledge", response_model=List[KnowledgeArticleResponse])
async def get_knowledge_articles(category: Optional[str] = None):
    """ì§€ì‹ ì•„í‹°í´ ëª©ë¡ ì¡°íšŒ."""
    articles = _knowledge_store

    if category:
        articles = [a for a in articles if a.get("category") == category]

    # ìµœì‹ ìˆœ ì •ë ¬
    articles = sorted(articles, key=lambda x: x.get("createdAt", ""), reverse=True)

    return articles


@router.post("/knowledge", response_model=KnowledgeArticleResponse)
async def create_knowledge_article(request: CreateKnowledgeArticleRequest):
    """ì§€ì‹ ì•„í‹°í´ ìƒì„±."""
    import uuid
    from datetime import datetime

    article = {
        "id": str(uuid.uuid4()),
        "title": request.title,
        "author": request.author,
        "category": request.category,
        "rawContent": request.rawContent,
        "structuredSummary": request.structuredSummary,
        "createdAt": datetime.now().strftime("%Y-%m-%d"),
    }

    _knowledge_store.append(article)
    logger.info(f"Created knowledge article: {article['title']}")

    return article


@router.delete("/knowledge/{article_id}")
async def delete_knowledge_article(article_id: str):
    """ì§€ì‹ ì•„í‹°í´ ì‚­ì œ."""
    global _knowledge_store

    original_count = len(_knowledge_store)
    _knowledge_store = [a for a in _knowledge_store if a.get("id") != article_id]

    if len(_knowledge_store) == original_count:
        raise HTTPException(status_code=404, detail="Article not found")

    logger.info(f"Deleted knowledge article: {article_id}")
    return {"success": True}


# ============================================
# í•™ìŠµ í‰ê°€ (Assessment)
# ============================================

class AssessmentSubmitRequest(BaseModel):
    """í€´ì¦ˆ ë‹µì•ˆ ì œì¶œ ìš”ì²­."""
    sessionId: str
    trackId: str
    levelId: Optional[str] = None
    answers: List[dict]  # [{"questionId": str, "choiceId": str}]


# íŠ¸ë™ ì •ì˜ (ì •ì  ë°ì´í„°)
ASSESSMENT_TRACKS = [
    {
        "id": "work_sense",
        "name": "ì—…ë¬´ ì„¼ìŠ¤ ì²´í¬",
        "description": "ê³ ê° ì‘ëŒ€, ì—…ë¬´ ìš°ì„ ìˆœìœ„, íŒ€ í˜‘ì—… ë“± ê¸°ë³¸ì ì¸ ì—…ë¬´ ì—­ëŸ‰ì„ í‰ê°€í•©ë‹ˆë‹¤.",
        "icon": "fas fa-lightbulb",
        "type": "work_sense",
    },
    {
        "id": "product_knowledge",
        "name": "ì œí’ˆ ì§€ì‹",
        "description": "ì‹œì¥ í¬ì§€ì…”ë‹ë¶€í„° ì„¸ë¶€ ê¸°ëŠ¥ê¹Œì§€, ì œí’ˆì— ëŒ€í•œ ì²´ê³„ì ì¸ í•™ìŠµê³¼ í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.",
        "icon": "fas fa-graduation-cap",
        "type": "product_knowledge",
        "totalLevels": 4,
    },
]

# ë ˆë²¨ ì •ì˜ (ì œí’ˆ ì§€ì‹ìš©)
ASSESSMENT_LEVELS = [
    {
        "id": "level_1",
        "trackId": "product_knowledge",
        "order": 1,
        "name": "ì‹œì¥ê³¼ í¬ì§€ì…”ë‹",
        "description": "ìš°ë¦¬ ì œí’ˆì´ ì†í•œ ì‹œì¥ê³¼ ê²½ìŸ í™˜ê²½ì„ ì´í•´í•©ë‹ˆë‹¤.",
        "passingScore": 80,
    },
    {
        "id": "level_2",
        "trackId": "product_knowledge",
        "order": 2,
        "name": "ì„¤ê³„ ì² í•™ê³¼ ëª©ì ",
        "description": "ì œí’ˆì´ í•´ê²°í•˜ëŠ” í•µì‹¬ ë¬¸ì œì™€ ì„¤ê³„ ì›ì¹™ì„ í•™ìŠµí•©ë‹ˆë‹¤.",
        "passingScore": 80,
    },
    {
        "id": "level_3",
        "trackId": "product_knowledge",
        "order": 3,
        "name": "í•µì‹¬ ê¸°ëŠ¥êµ° ì´í•´",
        "description": "ì£¼ìš” ê¸°ëŠ¥êµ°ì˜ í•„ìš”ì„±ê³¼ ì‘ë™ ë°©ì‹ì„ íŒŒì•…í•©ë‹ˆë‹¤.",
        "passingScore": 80,
    },
    {
        "id": "level_4",
        "trackId": "product_knowledge",
        "order": 4,
        "name": "ì„¸ë¶€ ê¸°ëŠ¥ ì‹¬í™”",
        "description": "ê° ê¸°ëŠ¥ì˜ ìƒì„¸ ì˜µì…˜ê³¼ ê³ ê¸‰ ì‚¬ìš©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.",
        "passingScore": 80,
    },
]

# ìƒ˜í”Œ ë¬¸ì œ (ì—…ë¬´ ì„¼ìŠ¤ ì²´í¬)
WORK_SENSE_QUESTIONS = [
    {
        "id": "ws_q1",
        "trackId": "work_sense",
        "type": "scenario",
        "context": "ê³ ê°ì´ ê¸‰í•˜ê²Œ ê¸°ëŠ¥ ìˆ˜ì •ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ í˜„ì¬ ë‹¤ë¥¸ ì¤‘ìš”í•œ í”„ë¡œì íŠ¸ ë§ˆê°ì´ ì½”ì•ì…ë‹ˆë‹¤.",
        "question": "ì´ ìƒí™©ì—ì„œ ê°€ì¥ ì ì ˆí•œ ëŒ€ì‘ì€?",
        "choices": [
            {"id": "a", "text": "ê³ ê° ìš”ì²­ì„ ìš°ì„  ì²˜ë¦¬í•˜ê³  í”„ë¡œì íŠ¸ ë§ˆê°ì„ ë¯¸ë£¬ë‹¤"},
            {"id": "b", "text": "í”„ë¡œì íŠ¸ ë§ˆê°ì„ ìš°ì„ í•˜ê³  ê³ ê°ì—ê²Œ ê¸°ë‹¤ë ¤ë‹¬ë¼ê³  í•œë‹¤"},
            {"id": "c", "text": "ìƒì‚¬ì—ê²Œ ìƒí™©ì„ ë³´ê³ í•˜ê³  ìš°ì„ ìˆœìœ„ ì¡°ì •ì„ ìš”ì²­í•œë‹¤"},
            {"id": "d", "text": "ë‘ ê°€ì§€ ëª¨ë‘ ì•¼ê·¼í•´ì„œ ì²˜ë¦¬í•œë‹¤"},
        ],
        "correctChoiceId": "c",
        "explanation": "ìš°ì„ ìˆœìœ„ ì¶©ëŒ ìƒí™©ì—ì„œëŠ” ë…ë‹¨ì ìœ¼ë¡œ ê²°ì •í•˜ê¸°ë³´ë‹¤ ìƒì‚¬ì—ê²Œ ìƒí™©ì„ ê³µìœ í•˜ê³  ì¡°ì§ ì°¨ì›ì˜ ìš°ì„ ìˆœìœ„ íŒë‹¨ì„ ë°›ëŠ” ê²ƒì´ ë°”ëŒì§í•©ë‹ˆë‹¤.",
    },
    {
        "id": "ws_q2",
        "trackId": "work_sense",
        "type": "scenario",
        "context": "íŒ€ íšŒì˜ ì¤‘ ë™ë£Œê°€ ì œì‹œí•œ ì•„ì´ë””ì–´ì— ëª…ë°±í•œ ë¬¸ì œì ì´ ë³´ì…ë‹ˆë‹¤.",
        "question": "ê°€ì¥ ì ì ˆí•œ ëŒ€ì‘ ë°©ë²•ì€?",
        "choices": [
            {"id": "a", "text": "íšŒì˜ ì¤‘ ì¦‰ì‹œ ë¬¸ì œì ì„ ì§€ì í•œë‹¤"},
            {"id": "b", "text": "íšŒì˜ í›„ ê°œì¸ì ìœ¼ë¡œ ë™ë£Œì—ê²Œ ì´ì•¼ê¸°í•œë‹¤"},
            {"id": "c", "text": "ë¬¸ì œì ê³¼ í•¨ê»˜ ê°œì„  ë°©ì•ˆì„ ê±´ì„¤ì ìœ¼ë¡œ ì œì•ˆí•œë‹¤"},
            {"id": "d", "text": "ë‹¤ë¥¸ ì‚¬ëŒì´ ì§€ì í•  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦°ë‹¤"},
        ],
        "correctChoiceId": "c",
        "explanation": "ë¬¸ì œì ë§Œ ì§€ì í•˜ê¸°ë³´ë‹¤ ê°œì„  ë°©ì•ˆê³¼ í•¨ê»˜ ê±´ì„¤ì ìœ¼ë¡œ ì˜ê²¬ì„ ë‚˜ëˆ„ëŠ” ê²ƒì´ íŒ€ í˜‘ì—…ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.",
    },
    {
        "id": "ws_q3",
        "trackId": "work_sense",
        "type": "scenario",
        "context": "ì²˜ìŒ ì ‘í•˜ëŠ” ì—…ë¬´ë¥¼ ë°°ì •ë°›ì•˜ëŠ”ë°, ë‹´ë‹¹ìê°€ íœ´ê°€ ì¤‘ì…ë‹ˆë‹¤.",
        "question": "ì–´ë–»ê²Œ ëŒ€ì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        "choices": [
            {"id": "a", "text": "ë‹´ë‹¹ìê°€ ëŒì•„ì˜¬ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦°ë‹¤"},
            {"id": "b", "text": "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ë³´ê³  ì‹œë„í•´ë³¸ í›„, ë§‰íˆëŠ” ë¶€ë¶„ì„ ì •ë¦¬í•œë‹¤"},
            {"id": "c", "text": "ë‹¤ë¥¸ íŒ€ì›ì—ê²Œ ì „ì²´ ì—…ë¬´ë¥¼ ëŒ€ì‹  í•´ë‹¬ë¼ê³  ìš”ì²­í•œë‹¤"},
            {"id": "d", "text": "ìƒì‚¬ì—ê²Œ ì—…ë¬´ë¥¼ ëª»í•˜ê² ë‹¤ê³  ë³´ê³ í•œë‹¤"},
        ],
        "correctChoiceId": "b",
        "explanation": "ë¨¼ì € ìŠ¤ìŠ¤ë¡œ ì¡°ì‚¬í•˜ê³  ì‹œë„í•´ë³¸ í›„ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ì •ë¦¬í•˜ë©´ íš¨ìœ¨ì ìœ¼ë¡œ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    },
]

# ì§„í–‰ë„ ì €ì¥ (ì¸ë©”ëª¨ë¦¬)
_assessment_progress: dict = {}

# í•™ìŠµ ì½˜í…ì¸  í”„ë¡¬í”„íŠ¸ (ë ˆë²¨ë³„)
LEARNING_CONTENT_PROMPTS = {
    "level_1": """ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ í•™ìŠµ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

## ì‹œì¥ê³¼ í¬ì§€ì…”ë‹

1. **ì‹œì¥ ì´í•´**: ìš°ë¦¬ ì œí’ˆì´ ì†í•œ ì‹œì¥ì˜ í˜„í™©ê³¼ íŠ¸ë Œë“œ
2. **ê²½ìŸ í™˜ê²½**: ì£¼ìš” ê²½ìŸì‚¬ì™€ ìš°ë¦¬ ì œí’ˆì˜ ì°¨ë³„ì 
3. **íƒ€ê²Ÿ ê³ ê°**: ìš°ë¦¬ ì œí’ˆì˜ ì£¼ìš” ê³ ê°êµ°ê³¼ ê·¸ë“¤ì˜ ë‹ˆì¦ˆ
4. **ê°€ì¹˜ ì œì•ˆ**: ìš°ë¦¬ ì œí’ˆì´ ì œê³µí•˜ëŠ” í•µì‹¬ ê°€ì¹˜

ì œí’ˆ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ, í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.""",

    "level_2": """ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ í•™ìŠµ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

## ì„¤ê³„ ì² í•™ê³¼ ëª©ì 

1. **í•µì‹¬ ë¬¸ì œ**: ìš°ë¦¬ ì œí’ˆì´ í•´ê²°í•˜ê³ ì í•˜ëŠ” í•µì‹¬ ë¬¸ì œ
2. **ì„¤ê³„ ì›ì¹™**: ì œí’ˆì„ ì„¤ê³„í•  ë•Œ ì ìš©ëœ ì£¼ìš” ì›ì¹™ë“¤
3. **ì•„í‚¤í…ì²˜ ê°œìš”**: ì‚¬ìš©ì ê´€ì ì—ì„œ ì œí’ˆì˜ êµ¬ì¡°
4. **ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤**: ì œí’ˆì˜ ëŒ€í‘œì ì¸ ì‚¬ìš© ì‚¬ë¡€

ì œí’ˆ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ 'ì™œ' ì´ë ‡ê²Œ ì„¤ê³„ë˜ì—ˆëŠ”ì§€ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ, í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.""",

    "level_3": """ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ í•™ìŠµ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

## í•µì‹¬ ê¸°ëŠ¥êµ° ì´í•´

ê° ì£¼ìš” ê¸°ëŠ¥êµ°ì— ëŒ€í•´:
1. **ì™œ í•„ìš”í•œê°€?**: ì´ ê¸°ëŠ¥ì´ ì¡´ì¬í•˜ëŠ” ì´ìœ 
2. **ë¬´ì—‡ì¸ê°€?**: ê¸°ëŠ¥ì˜ ê°œìš”ì™€ í•µì‹¬ ê°œë…
3. **ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜?**: ê¸°ë³¸ì ì¸ ì‚¬ìš© ë°©ë²•
4. **ë‹¤ë¥¸ ê¸°ëŠ¥ê³¼ì˜ ì—°ê²°**: ê¸°ëŠ¥ ê°„ ê´€ê³„

ì œí’ˆ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì‹¤ì œ ì—…ë¬´ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ê´€ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ, í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.""",

    "level_4": """ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ í•™ìŠµ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

## ì„¸ë¶€ ê¸°ëŠ¥ ì‹¬í™”

1. **ìƒì„¸ ì˜µì…˜**: ê° ê¸°ëŠ¥ì˜ ì„¸ë¶€ ì„¤ì •ê³¼ ì˜µì…˜ë“¤
2. **ê³ ê¸‰ ì‚¬ìš©ë²•**: íŒŒì›Œ ìœ ì €ë¥¼ ìœ„í•œ í™œìš© íŒ
3. **íŠ¸ëŸ¬ë¸”ìŠˆíŒ…**: ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²° ë°©ë²•
4. **ì‹¤ì „ í™œìš© íŒ**: íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë…¸í•˜ìš°

ì œí’ˆ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ, í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.""",
}


@router.get("/assessment/tracks")
async def get_assessment_tracks():
    """í•™ìŠµ í‰ê°€ íŠ¸ë™ ëª©ë¡ ì¡°íšŒ."""
    return ASSESSMENT_TRACKS


@router.get("/assessment/tracks/{track_id}/levels")
async def get_assessment_levels(
    track_id: str,
    sessionId: str = Query(...),
):
    """íŠ¸ë™ì˜ ë ˆë²¨ ëª©ë¡ ì¡°íšŒ (ì§„í–‰ë„ í¬í•¨)."""
    levels = [l for l in ASSESSMENT_LEVELS if l["trackId"] == track_id]

    # ì§„í–‰ë„ ì¡°íšŒ
    session_progress = _assessment_progress.get(sessionId, {})
    track_progress = session_progress.get(track_id, {})

    result = []
    for level in levels:
        level_progress = track_progress.get(level["id"], {})
        is_completed = level_progress.get("isPassed", False)
        score = level_progress.get("score", 0)

        # ì²« ë²ˆì§¸ ë ˆë²¨ì€ í•­ìƒ ì–¸ë½, ì´í›„ëŠ” ì´ì „ ë ˆë²¨ ì™„ë£Œ ì‹œ ì–¸ë½
        is_unlocked = level["order"] == 1
        if level["order"] > 1:
            prev_level_id = f"level_{level['order'] - 1}"
            prev_progress = track_progress.get(prev_level_id, {})
            is_unlocked = prev_progress.get("isPassed", False)

        result.append({
            **level,
            "isUnlocked": is_unlocked,
            "isCompleted": is_completed,
            "score": score,
        })

    return result


@router.get("/assessment/learn/{track_id}/{level_id}/stream")
async def stream_learning_content(
    track_id: str,
    level_id: str,
):
    """í•™ìŠµ ì½˜í…ì¸  ìŠ¤íŠ¸ë¦¬ë° (RAG ê¸°ë°˜)."""

    prompt = LEARNING_CONTENT_PROMPTS.get(level_id)
    if not prompt:
        raise HTTPException(status_code=404, detail="Level not found")

    async def event_generator():
        try:
            client = get_gemini_client()

            # RAG ìŠ¤í† ì–´ ì„¤ì •
            from google.genai import types

            rag_stores = []
            if STORE_PRODUCT:
                rag_stores.append(STORE_PRODUCT)

            tools = None
            if rag_stores:
                tools = [
                    types.Tool(
                        file_search=types.FileSearch(
                            file_search_store_names=rag_stores
                        )
                    )
                ]

            generation_config = types.GenerateContentConfig(
                thinking_config=types.ThinkingConfig(thinking_budget=0),
                tools=tools,
            )

            full_response = ""
            model_name = client.models[0]

            response = client.client.models.generate_content_stream(
                model=model_name,
                contents=prompt,
                config=generation_config,
            )

            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    yield format_sse("chunk", {"text": chunk.text})

            yield format_sse("result", {"text": full_response})

        except Exception as e:
            logger.error(f"Learning content stream error: {e}")
            yield format_sse("error", {"message": str(e)})

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )


@router.get("/assessment/mentor/chat/stream")
async def stream_mentor_chat(
    sessionId: str = Query(...),
    trackId: str = Query(...),
    levelId: str = Query(...),
    message: str = Query(...),
):
    """AI ë©˜í†  ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° (ë ˆë²¨ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)."""

    # ë ˆë²¨ ì •ë³´ ì¡°íšŒ
    level_info = next((l for l in ASSESSMENT_LEVELS if l["id"] == levelId), None)
    level_name = level_info["name"] if level_info else "í•™ìŠµ"
    level_desc = level_info["description"] if level_info else ""

    system_prompt = f"""ë‹¹ì‹ ì€ ì˜¨ë³´ë”© í•™ìŠµ ë©˜í† ì…ë‹ˆë‹¤.
í˜„ì¬ í•™ìŠµìëŠ” '{level_name}' ë ˆë²¨ì„ í•™ìŠµ ì¤‘ì…ë‹ˆë‹¤.
ë ˆë²¨ ì„¤ëª…: {level_desc}

ì œí’ˆ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ í•™ìŠµìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ í•œêµ­ì–´ë¡œ, ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì¸ì‚¬ë§ì´ë‚˜ ì´ë¦„ ì–¸ê¸‰ ì—†ì´ ë°”ë¡œ ë³¸ë¡ ìœ¼ë¡œ ë“¤ì–´ê°€ì„¸ìš”."""

    async def event_generator():
        try:
            client = get_gemini_client()

            # RAG ìŠ¤í† ì–´ ì„¤ì •
            from google.genai import types

            rag_stores = []
            if STORE_PRODUCT:
                rag_stores.append(STORE_PRODUCT)

            tools = None
            if rag_stores:
                tools = [
                    types.Tool(
                        file_search=types.FileSearch(
                            file_search_store_names=rag_stores
                        )
                    )
                ]

            messages = [
                {"role": "user", "parts": [{"text": system_prompt}]},
                {"role": "model", "parts": [{"text": "ë„¤, ì§ˆë¬¸í•´ì£¼ì„¸ìš”."}]},
                {"role": "user", "parts": [{"text": message}]},
            ]

            generation_config = types.GenerateContentConfig(
                thinking_config=types.ThinkingConfig(thinking_budget=0),
                tools=tools,
            )

            full_response = ""
            model_name = client.models[0]

            response = client.client.models.generate_content_stream(
                model=model_name,
                contents=messages,
                config=generation_config,
            )

            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    yield format_sse("chunk", {"text": chunk.text})

            yield format_sse("result", {"text": full_response})

        except Exception as e:
            logger.error(f"Mentor chat stream error: {e}")
            yield format_sse("error", {"message": str(e)})

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )


@router.get("/assessment/questions/{track_id}")
async def get_assessment_questions(
    track_id: str,
    levelId: Optional[str] = None,
):
    """í€´ì¦ˆ ë¬¸ì œ ì¡°íšŒ."""
    if track_id == "work_sense":
        questions = WORK_SENSE_QUESTIONS
    else:
        # ì œí’ˆ ì§€ì‹ ë¬¸ì œëŠ” AIë¡œ ë™ì  ìƒì„± (ì¶”í›„ êµ¬í˜„)
        # í˜„ì¬ëŠ” ìƒ˜í”Œ ë°˜í™˜
        questions = []

    # ì •ë‹µ ì •ë³´ ì œì™¸í•˜ê³  ë°˜í™˜
    return [
        {
            "id": q["id"],
            "trackId": q["trackId"],
            "type": q["type"],
            "context": q.get("context"),
            "question": q["question"],
            "choices": q["choices"],
        }
        for q in questions
    ]


@router.post("/assessment/submit")
async def submit_assessment(request: AssessmentSubmitRequest):
    """í€´ì¦ˆ ë‹µì•ˆ ì œì¶œ ë° ì±„ì ."""

    # ë¬¸ì œ ì¡°íšŒ
    if request.trackId == "work_sense":
        questions = {q["id"]: q for q in WORK_SENSE_QUESTIONS}
    else:
        questions = {}

    # ì±„ì 
    correct_count = 0
    results = []

    for answer in request.answers:
        question = questions.get(answer["questionId"])
        if question:
            is_correct = answer["choiceId"] == question["correctChoiceId"]
            if is_correct:
                correct_count += 1

            results.append({
                "questionId": answer["questionId"],
                "choiceId": answer["choiceId"],
                "isCorrect": is_correct,
                "correctChoiceId": question["correctChoiceId"],
                "explanation": question["explanation"],
            })

    total = len(request.answers)
    score = int((correct_count / total) * 100) if total > 0 else 0
    is_passed = score >= 80

    # ì§„í–‰ë„ ì €ì¥
    if request.sessionId not in _assessment_progress:
        _assessment_progress[request.sessionId] = {}
    if request.trackId not in _assessment_progress[request.sessionId]:
        _assessment_progress[request.sessionId][request.trackId] = {}

    level_key = request.levelId or "default"
    _assessment_progress[request.sessionId][request.trackId][level_key] = {
        "score": score,
        "isPassed": is_passed,
        "completedAt": __import__("datetime").datetime.now().isoformat(),
    }

    logger.info(f"Assessment submitted: session={request.sessionId}, track={request.trackId}, score={score}")

    return {
        "trackId": request.trackId,
        "levelId": request.levelId,
        "score": score,
        "totalQuestions": total,
        "correctCount": correct_count,
        "isPassed": is_passed,
        "answers": results,
    }


@router.get("/assessment/progress/{session_id}")
async def get_assessment_progress(session_id: str):
    """ì§„í–‰ë„ ì¡°íšŒ."""
    progress = _assessment_progress.get(session_id, {})

    tracks = []
    for track_id, levels in progress.items():
        for level_id, data in levels.items():
            tracks.append({
                "trackId": track_id,
                "levelId": level_id if level_id != "default" else None,
                "score": data.get("score", 0),
                "isPassed": data.get("isPassed", False),
                "completedAt": data.get("completedAt"),
            })

    return {"tracks": tracks}


# ============================================
# ì œí’ˆë³„ ì§€ì‹ í•™ìŠµ (Product Knowledge)
# ============================================

# ì§€ì› ì œí’ˆ ëª©ë¡
PRODUCTS = [
    {
        "id": "freshservice",
        "name": "Freshservice",
        "name_ko": "í”„ë ˆì‹œì„œë¹„ìŠ¤",
        "description": "IT Service Management",
        "description_ko": "IT ì„œë¹„ìŠ¤ ê´€ë¦¬",
        "icon": "cog",
        "color": "blue",
    },
    {
        "id": "freshdesk",
        "name": "Freshdesk",
        "name_ko": "í”„ë ˆì‹œë°ìŠ¤í¬",
        "description": "Customer Support (Omni í¬í•¨)",
        "description_ko": "ê³ ê° ì§€ì› (Omni í¬í•¨)",
        "icon": "headset",
        "color": "green",
    },
    {
        "id": "freshsales",
        "name": "Freshsales",
        "name_ko": "í”„ë ˆì‹œì„¸ì¼ì¦ˆ",
        "description": "CRM & Sales",
        "description_ko": "CRM ë° ì˜ì—…",
        "icon": "chart-line",
        "color": "purple",
    },
    {
        "id": "freshchat",
        "name": "Freshchat",
        "name_ko": "í”„ë ˆì‹œì±—",
        "description": "Messaging & Chat",
        "description_ko": "ë©”ì‹œì§• ë° ì±„íŒ…",
        "icon": "comments",
        "color": "orange",
    },
]


@router.get("/products")
async def get_products():
    """ì§€ì› ì œí’ˆ ëª©ë¡ ì¡°íšŒ."""
    return PRODUCTS


@router.get("/products/{product_id}")
async def get_product(product_id: str):
    """ë‹¨ì¼ ì œí’ˆ ì •ë³´ ì¡°íšŒ."""
    product = next((p for p in PRODUCTS if p["id"] == product_id), None)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    return product


@router.get("/products/{product_id}/categories")
async def get_product_categories(product_id: str):
    """ì œí’ˆë³„ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ (Supabase kb_categories)."""
    try:
        kb_client = get_kb_client()
        categories = kb_client.get_categories(product_id)

        # í”„ë¡ íŠ¸ì—”ë“œ ì¹œí™”ì  í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return [
            {
                "id": cat["id"],
                "name": cat.get("name_ko") or cat["name_en"],
                "nameEn": cat["name_en"],
                "nameKo": cat.get("name_ko"),
                "slug": cat["slug"],
                "description": cat.get("description_ko") or cat.get("description_en"),
                "displayOrder": cat["display_order"],
            }
            for cat in categories
        ]
    except Exception as e:
        logger.error(f"Failed to get categories for {product_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/products/{product_id}/categories/{category_slug}")
async def get_product_category(product_id: str, category_slug: str):
    """ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ ìƒì„¸ ì¡°íšŒ."""
    try:
        kb_client = get_kb_client()
        category = kb_client.get_category_by_slug(product_id, category_slug)

        if not category:
            raise HTTPException(status_code=404, detail="Category not found")

        return {
            "id": category["id"],
            "name": category.get("name_ko") or category["name_en"],
            "nameEn": category["name_en"],
            "nameKo": category.get("name_ko"),
            "slug": category["slug"],
            "description": category.get("description_ko") or category.get("description_en"),
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get category {category_slug}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/products/{product_id}/categories/{category_slug}/folders")
async def get_category_folders(product_id: str, category_slug: str):
    """ì¹´í…Œê³ ë¦¬ ë‚´ í´ë” ëª©ë¡ ì¡°íšŒ."""
    try:
        kb_client = get_kb_client()

        # ë¨¼ì € ì¹´í…Œê³ ë¦¬ ID ì¡°íšŒ
        category = kb_client.get_category_by_slug(product_id, category_slug)
        if not category:
            raise HTTPException(status_code=404, detail="Category not found")

        folders = kb_client.get_folders_by_category(product_id, category["id"])

        return [
            {
                "id": folder["id"],
                "name": folder.get("name_ko") or folder["name_en"],
                "nameEn": folder["name_en"],
                "nameKo": folder.get("name_ko"),
                "slug": folder["slug"],
                "displayOrder": folder["display_order"],
            }
            for folder in folders
        ]
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get folders for {category_slug}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/products/{product_id}/categories/{category_slug}/documents")
async def get_category_documents(product_id: str, category_slug: str, limit: int = 50):
    """ì¹´í…Œê³ ë¦¬ ë‚´ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ."""
    try:
        kb_client = get_kb_client()

        # ë¨¼ì € ì¹´í…Œê³ ë¦¬ ID ì¡°íšŒ
        category = kb_client.get_category_by_slug(product_id, category_slug)
        if not category:
            raise HTTPException(status_code=404, detail="Category not found")

        documents = kb_client.get_documents_by_category(product_id, category["id"], limit)

        return [
            {
                "id": doc["id"],
                "csvId": doc["csv_id"],
                "title": doc.get("title_ko") or doc["title_en"],
                "titleEn": doc["title_en"],
                "titleKo": doc.get("title_ko"),
                "slug": doc.get("short_slug") or doc["slug"],
                "folderId": doc.get("folder_id"),
            }
            for doc in documents
        ]
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get documents for {category_slug}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/products/{product_id}/stats")
async def get_product_stats(product_id: str):
    """ì œí’ˆë³„ ë¬¸ì„œ í†µê³„ ì¡°íšŒ."""
    try:
        kb_client = get_kb_client()
        stats = kb_client.get_product_stats(product_id)
        return stats
    except Exception as e:
        logger.error(f"Failed to get stats for {product_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ì œí’ˆë³„ í•™ìŠµ ì½˜í…ì¸  ìŠ¤íŠ¸ë¦¬ë°
# ============================================

def format_documents_for_context(documents: List[dict], max_chars: int = 8000) -> str:
    """ë¬¸ì„œ ëª©ë¡ì„ AI ì»¨í…ìŠ¤íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜."""
    context_parts = []
    total_chars = 0

    for doc in documents:
        title = doc.get("title_ko") or doc.get("title_en", "")
        content = doc.get("content_text_ko") or doc.get("content_text_en", "")

        # ë¬¸ì„œë³„ ìµœëŒ€ ê¸¸ì´ ì œí•œ
        if len(content) > 2000:
            content = content[:2000] + "..."

        doc_text = f"### {title}\n{content}\n"

        if total_chars + len(doc_text) > max_chars:
            break

        context_parts.append(doc_text)
        total_chars += len(doc_text)

    return "\n".join(context_parts)


@router.get("/products/{product_id}/categories/{category_slug}/learn/stream")
async def stream_category_learning(
    product_id: str,
    category_slug: str,
):
    """ì¹´í…Œê³ ë¦¬ë³„ í•™ìŠµ ì½˜í…ì¸  ìŠ¤íŠ¸ë¦¬ë° (Supabase ë¬¸ì„œ ê¸°ë°˜)."""
    try:
        kb_client = get_kb_client()

        # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¡°íšŒ
        category = kb_client.get_category_by_slug(product_id, category_slug)
        if not category:
            raise HTTPException(status_code=404, detail="Category not found")

        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ë¬¸ì„œ ì¡°íšŒ
        documents = kb_client.get_documents_by_category(product_id, category["id"], limit=10)

        if not documents:
            raise HTTPException(status_code=404, detail="No documents found for this category")

        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = format_documents_for_context(documents)
        category_name = category.get("name_ko") or category["name_en"]

        # í•™ìŠµ ì½˜í…ì¸  ìƒì„± í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¹ì‹ ì€ IT ì†”ë£¨ì…˜ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ '{category_name}' ì¹´í…Œê³ ë¦¬ì˜ ë¬¸ì„œì…ë‹ˆë‹¤.

---
{context}
---

ìœ„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ì…ì‚¬ì›ì„ ìœ„í•œ í•™ìŠµ ì½˜í…ì¸ ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

í¬í•¨í•  ë‚´ìš©:
1. **ê°œìš”**: ì´ ê¸°ëŠ¥ì´ ì™œ í•„ìš”í•œì§€, ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜
2. **í•µì‹¬ ê°œë…**: ì•Œì•„ì•¼ í•  ì£¼ìš” ìš©ì–´ì™€ ê°œë…
3. **ì£¼ìš” ê¸°ëŠ¥**: í•µì‹¬ ê¸°ëŠ¥ë“¤ì˜ ì„¤ëª…
4. **ì‚¬ìš© ë°©ë²•**: ë‹¨ê³„ë³„ ì‚¬ìš© ê°€ì´ë“œ
5. **ì‹¤ë¬´ íŒ**: íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ë°©ë²•
6. **ìì£¼ ë¬»ëŠ” ì§ˆë¬¸**: ì˜ˆìƒë˜ëŠ” ì§ˆë¬¸ê³¼ ë‹µë³€

ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ, í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”."""

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to prepare learning content: {e}")
        raise HTTPException(status_code=500, detail=str(e))

    async def event_generator():
        try:
            client = get_gemini_client()

            from google.genai import types

            generation_config = types.GenerateContentConfig(
                thinking_config=types.ThinkingConfig(thinking_budget=0),
            )

            full_response = ""
            model_name = client.models[0]

            response = client.client.models.generate_content_stream(
                model=model_name,
                contents=prompt,
                config=generation_config,
            )

            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    yield format_sse("chunk", {"text": chunk.text})

            yield format_sse("result", {"text": full_response})

        except Exception as e:
            logger.error(f"Learning content stream error: {e}")
            yield format_sse("error", {"message": str(e)})

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )


# ============================================
# ì œí’ˆë³„ AI ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë°
# ============================================

@router.get("/products/{product_id}/chat/stream")
async def stream_product_chat(
    product_id: str,
    message: str = Query(..., description="ì‚¬ìš©ì ì§ˆë¬¸"),
    sessionId: Optional[str] = Query(None, description="ì„¸ì…˜ ID"),
    categorySlug: Optional[str] = Query(None, description="ì¹´í…Œê³ ë¦¬ ìŠ¬ëŸ¬ê·¸ (ì„ íƒ)"),
):
    """ì œí’ˆë³„ AI ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° (Supabase ë¬¸ì„œ ê¸°ë°˜).

    categorySlugì´ ì œê³µë˜ë©´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë‚´ ë¬¸ì„œë§Œ ê²€ìƒ‰,
    ì—†ìœ¼ë©´ ì œí’ˆ ì „ì²´ ë¬¸ì„œì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    try:
        kb_client = get_kb_client()
        product = next((p for p in PRODUCTS if p["id"] == product_id), None)

        if not product:
            raise HTTPException(status_code=404, detail="Product not found")

        product_name = product.get("name_ko") or product["name"]

        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§ (ì„ íƒ)
        category_context = ""
        if categorySlug:
            category = kb_client.get_category_by_slug(product_id, categorySlug)
            if category:
                documents = kb_client.get_documents_by_category(product_id, category["id"], limit=5)
                category_name = category.get("name_ko") or category["name_en"]
                category_context = f"\ní˜„ì¬ í•™ìŠµ ì¤‘ì¸ ì¹´í…Œê³ ë¦¬: {category_name}\n"
            else:
                documents = []
        else:
            # í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
            documents = kb_client.text_search(message, product_filter=product_id, limit=5)

        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = format_documents_for_context(documents) if documents else "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = f"""ë‹¹ì‹ ì€ {product_name} ì œí’ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.{category_context}

ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:

---
{context}
---

ë‹µë³€ ê·œì¹™:
- í•œêµ­ì–´ë¡œ ë‹µë³€
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì‚¬ìš©
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "í•´ë‹¹ ì •ë³´ëŠ” ë¬¸ì„œì—ì„œ í™•ì¸ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€
- ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ë³¸ë¡ ìœ¼ë¡œ"""

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to prepare chat: {e}")
        raise HTTPException(status_code=500, detail=str(e))

    async def event_generator():
        try:
            client = get_gemini_client()

            from google.genai import types

            messages = [
                {"role": "user", "parts": [{"text": system_prompt}]},
                {"role": "model", "parts": [{"text": "ë„¤, ë¬´ì—‡ì´ë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”."}]},
                {"role": "user", "parts": [{"text": message}]},
            ]

            generation_config = types.GenerateContentConfig(
                thinking_config=types.ThinkingConfig(thinking_budget=0),
            )

            full_response = ""
            model_name = client.models[0]

            response = client.client.models.generate_content_stream(
                model=model_name,
                contents=messages,
                config=generation_config,
            )

            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    yield format_sse("chunk", {"text": chunk.text})

            yield format_sse("result", {"text": full_response})

        except Exception as e:
            logger.error(f"Product chat stream error: {e}")
            yield format_sse("error", {"message": str(e)})

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )
