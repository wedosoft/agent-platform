"""ì˜¨ë³´ë”© ì „ìš© API ë¼ìš°í„°."""

import json
import logging
from typing import List, Optional

from fastapi import APIRouter, HTTPException, Query, UploadFile, File, Form
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

from app.services.gemini_client import get_gemini_client
from app.services.gemini_file_search import upload_document_to_store, get_store_documents
from app.services.onboarding_repository import get_onboarding_repository
from app.core.config import get_settings

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/onboarding", tags=["onboarding"])

settings = get_settings()

# ì˜¨ë³´ë”©ì—ì„œ ì‚¬ìš©í•  RAG ìŠ¤í† ì–´ë“¤
STORE_PRODUCT = settings.gemini_store_common      # ì œí’ˆ ì§€ì‹ (Freshworks, Google ë“±)
STORE_HANDOVER = settings.gemini_store_onboarding  # ì¸ìˆ˜ì¸ê³„/í”„ë¡œì„¸ìŠ¤ ë¬¸ì„œ


# ============================================
# Request/Response Models
# ============================================

class CreateSessionRequest(BaseModel):
    """ì„¸ì…˜ ìƒì„± ìš”ì²­."""
    userName: str


class CreateSessionResponse(BaseModel):
    """ì„¸ì…˜ ìƒì„± ì‘ë‹µ."""
    sessionId: str
    message: str


class SaveProgressRequest(BaseModel):
    """ì§„í–‰ë„ ì €ì¥ ìš”ì²­."""
    sessionId: str
    scenarioId: str
    choiceId: str
    feedbackRating: Optional[int] = None


# ============================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# ============================================

MENTOR_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ìµœìƒìœ„ í…Œí¬ ê¸°ì—…ì˜ ì‹œë‹ˆì–´ ë©˜í†  'ì˜¨ë³´ë”© ë‚˜ì¹¨ë°˜'ì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ íŠ¹ì§•:
- ê°„ê²°í•˜ê³  ë³¸ë¡  ì¤‘ì‹¬ì˜ ë‹µë³€ (ì¸ì‚¬ë§ì´ë‚˜ ì´ë¦„ ì–¸ê¸‰ ì—†ì´ ë°”ë¡œ í•µì‹¬ìœ¼ë¡œ)
- ì‹¤ì§ˆì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸
- ìƒì‚°ì„±, ì‹œê°„ ê´€ë¦¬, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ë¬¸ì œ í•´ê²°, í˜‘ì—…ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹
- í•œêµ­ì–´ë¡œ ë‹µë³€

ì§ˆë¬¸ì— ëŒ€í•´ ë°”ë¡œ ë³¸ë¡ ìœ¼ë¡œ ë“¤ì–´ê°€ì„œ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”. ì´ë¦„ì„ ë¶€ë¥´ê±°ë‚˜ ì¸ì‚¬ë§ì„ í•˜ì§€ ë§ˆì„¸ìš”."""


def get_feedback_prompt(
    user_name: str,
    scenario_title: str,
    scenario_description: str,
    all_choices: List[str],
    selected_choice: str
) -> str:
    """ì‹œë‚˜ë¦¬ì˜¤ í”¼ë“œë°± ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸."""
    all_choices_text = '\n'.join(f'- {choice}' for choice in all_choices)
    
    return f"""ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ìµœìƒìœ„ í…Œí¬ ê¸°ì—…ì˜ ë…¸ë ¨í•œ ì‹œë‹ˆì–´ ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.

ì—…ë¬´ ì‹œë‚˜ë¦¬ì˜¤:
**ì œëª©:** {scenario_title}
**ìƒí™©:** {scenario_description}

ì„ íƒ ê°€ëŠ¥í•œ í–‰ë™ë“¤:
{all_choices_text}

**ì„ íƒí•œ í–‰ë™:** "{selected_choice}"

ì´ ì„ íƒì— ëŒ€í•´ ëª…í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°±ì„ ì œê³µí•´ ì£¼ì„¸ìš”.
**ì¤‘ìš”: ì´ë¦„ì„ ë¶€ë¥´ê±°ë‚˜ ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ë³¸ë¡ ìœ¼ë¡œ ë“¤ì–´ê°€ì„¸ìš”.**
**í”¼ë“œë°±ì€ ë°˜ë“œì‹œ ì•„ë˜ì˜ ë§ˆí¬ë‹¤ìš´ ì„œì‹ì„ ì •í™•íˆ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.**

### ğŸ¤· ì„ íƒì— ëŒ€í•œ ë¶„ì„
(ì„ íƒì„ ì¸ì •í•˜ê³ , ì‹¤ì œ ì—…ë¬´ í™˜ê²½ì—ì„œ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì¥ì ê³¼ ë‹¨ì ì„ ê· í˜• ìˆê²Œ ë¶„ì„)

---

### ğŸ’¡ ì¶”ì²œí•˜ëŠ” ì ‘ê·¼ ë°©ì‹
(ì´ ì‹œë‚˜ë¦¬ì˜¤ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ê°€ì¥ íš¨ê³¼ì ì¸ ì—…ë¬´ ì›ì¹™ì´ë‚˜ ì‚¬ê³  ëª¨ë¸ ì„¤ëª…. ê°€ì¥ ì´ìƒì ì¸ í–‰ë™ê³¼ ê·¸ ì´ìœ ë¥¼ ëª…í™•íˆ ì œì‹œ)

---

### ğŸ¤” ë‹¤ë¥¸ ì„ íƒì§€ë“¤ì— ëŒ€í•œ ê³ ì°°
(ì„ íƒë˜ì§€ ì•Šì€ ë‹¤ë¥¸ ì˜µì…˜ë“¤ì´ ì™œ ëœ íš¨ê³¼ì ì¸ì§€ ê°„ëµí•˜ê²Œ ì„¤ëª…)

---

### â­ í•µì‹¬ ì •ë¦¬
> (ì•ìœ¼ë¡œ ìœ ì‚¬í•œ ìƒí™©ì—ì„œ ê¸°ì–µí•˜ê³  ì ìš©í•  ìˆ˜ ìˆëŠ” í•µì‹¬ ì›ì¹™ì´ë‚˜ êµí›ˆì„ blockquote í˜•ì‹ìœ¼ë¡œ ì‘ì„±)

**í”¼ë“œë°± ì‘ì„±ì´ ëë‚˜ë©´, ë°˜ë“œì‹œ ë‹¤ìŒ ì¤„ì— %%%QUESTIONS%%% ë¼ëŠ” êµ¬ë¶„ìë¥¼ ì‚½ì…í•´ì£¼ì„¸ìš”.**

ê·¸ ë‹¤ìŒ ì¤„ë¶€í„°, ì´ ì£¼ì œì— ëŒ€í•´ ë” ê¹Šì´ ìƒê°í•´ë³¼ ìˆ˜ ìˆëŠ” 3ê°œì˜ ì—°ê´€ ì§ˆë¬¸ì„ ê°ê° í•œ ì¤„ì”© ì‘ì„±í•´ì£¼ì„¸ìš”. ì§ˆë¬¸ ì•ì—ëŠ” ë²ˆí˜¸ë‚˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¥¼ ë¶™ì´ì§€ ë§ˆì„¸ìš”."""


def get_followup_prompt(
    user_name: str,
    scenario_title: str,
    scenario_description: str,
    original_feedback: str,
    question: str
) -> str:
    """í›„ì† ì§ˆë¬¸ ë‹µë³€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸."""
    return f"""ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ìµœìƒìœ„ í…Œí¬ ê¸°ì—…ì˜ ì‹œë‹ˆì–´ ë©˜í† ì…ë‹ˆë‹¤.

**ìƒí™©:**
- **ì‹œë‚˜ë¦¬ì˜¤:** {scenario_title} ({scenario_description})
- **ì´ì „ ì¡°ì–¸ ìš”ì•½:** {original_feedback[:500]}...

**ì¶”ê°€ ì§ˆë¬¸:** "{question}"

ì´ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³ , ì‹¤ì§ˆì ì´ë©°, ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
**ì¤‘ìš”: ì´ë¦„ì„ ë¶€ë¥´ê±°ë‚˜ ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ë³¸ë¡ ìœ¼ë¡œ ë“¤ì–´ê°€ì„¸ìš”.**
ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ, í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”."""


# ============================================
# SSE í—¬í¼
# ============================================

def format_sse(event: str, data: dict) -> str:
    """SSE í¬ë§·ìœ¼ë¡œ ë³€í™˜."""
    return f"event: {event}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"


# ============================================
# ì„¸ì…˜ ê´€ë¦¬ (Supabase ì˜ì†í™”, í´ë°±: ì¸ë©”ëª¨ë¦¬)
# ============================================

# ëŒ€í™” íˆìŠ¤í† ë¦¬ìš© ì¸ë©”ëª¨ë¦¬ ìºì‹œ (ì„¸ì…˜ ë©”íƒ€ë°ì´í„°ëŠ” Supabaseì— ì €ì¥)
_conversation_cache: dict = {}


@router.post("/session", response_model=CreateSessionResponse)
async def create_session(request: CreateSessionRequest):
    """ì˜¨ë³´ë”© ì„¸ì…˜ ìƒì„±."""
    import uuid
    session_id = f"onboarding-{uuid.uuid4().hex[:8]}"

    # Supabaseì— ì„¸ì…˜ ì €ì¥ (ë˜ëŠ” ì¸ë©”ëª¨ë¦¬ í´ë°±)
    repo = get_onboarding_repository()
    await repo.create_session(session_id, request.userName)

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìºì‹œ ì´ˆê¸°í™”
    _conversation_cache[session_id] = {
        "userName": request.userName,
        "conversationHistory": [],
    }

    logger.info(f"Created onboarding session: {session_id} for user: {request.userName}")

    return CreateSessionResponse(
        sessionId=session_id,
        message="ì˜¨ë³´ë”© ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
    )


# ============================================
# ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° (AI ë©˜í† )
# ============================================

@router.get("/chat/stream")
async def chat_stream(
    sessionId: str = Query(...),
    query: str = Query(...),
):
    """AI ë©˜í†  ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° (RAG ê²€ìƒ‰ í¬í•¨)."""

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìºì‹œì—ì„œ ì¡°íšŒ, ì—†ìœ¼ë©´ Supabaseì—ì„œ ì„¸ì…˜ ì •ë³´ ì¡°íšŒ
    session = _conversation_cache.get(sessionId)
    if not session:
        repo = get_onboarding_repository()
        db_session = await repo.get_session(sessionId)
        user_name = db_session.user_name if db_session else "ì‹ ì…ì‚¬ì›"
        session = {"userName": user_name, "conversationHistory": []}
        _conversation_cache[sessionId] = session

    user_name = session.get("userName", "ì‹ ì…ì‚¬ì›")
    history = session.get("conversationHistory", [])
    
    # ì‚¬ìš©í•  RAG ìŠ¤í† ì–´ ëª©ë¡
    rag_stores = []
    if STORE_PRODUCT:
        rag_stores.append(STORE_PRODUCT)
    if STORE_HANDOVER:
        rag_stores.append(STORE_HANDOVER)
    
    async def event_generator():
        try:
            client = get_gemini_client()
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
            messages = [
                {"role": "user", "parts": [{"text": MENTOR_SYSTEM_PROMPT}]},
                {"role": "model", "parts": [{"text": "ë„¤, ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."}]},
            ]
            
            # íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 4í„´)
            for turn in history[-4:]:
                messages.append({"role": "user", "parts": [{"text": turn.get("user", "")}]})
                messages.append({"role": "model", "parts": [{"text": turn.get("model", "")}]})
            
            # í˜„ì¬ ì§ˆë¬¸
            messages.append({"role": "user", "parts": [{"text": query}]})
            
            # RAG ê²€ìƒ‰ ì„¤ì • (ì—¬ëŸ¬ ìŠ¤í† ì–´ ë™ì‹œ ê²€ìƒ‰)
            from google.genai import types

            # ìŠ¤í† ì–´ê°€ ìˆìœ¼ë©´ íŒŒì¼ ê²€ìƒ‰ ë„êµ¬ ì¶”ê°€
            tools = None
            if rag_stores:
                tools = [
                    types.Tool(
                        file_search=types.FileSearch(
                            file_search_store_names=rag_stores
                        )
                    )
                ]

            generation_config = types.GenerateContentConfig(
                thinking_config=types.ThinkingConfig(thinking_budget=0),
                tools=tools,
            )

            full_response = ""

            # ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
            model_name = client.models[0]
            response = client.client.models.generate_content_stream(
                model=model_name,
                contents=messages,
                config=generation_config,
            )
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    yield format_sse("chunk", {"text": chunk.text})
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            history.append({"user": query, "model": full_response})
            session["conversationHistory"] = history[-10:]  # ìµœê·¼ 10í„´ë§Œ ìœ ì§€
            
            yield format_sse("result", {"text": full_response})
            
        except Exception as e:
            logger.error(f"Chat stream error: {e}")
            yield format_sse("error", {"message": str(e)})
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )


# ============================================
# ì‹œë‚˜ë¦¬ì˜¤ í”¼ë“œë°± ìŠ¤íŠ¸ë¦¬ë°
# ============================================

@router.get("/feedback/stream")
async def feedback_stream(
    sessionId: str = Query(...),
    scenarioId: str = Query(...),
    scenarioTitle: str = Query(...),
    scenarioDescription: str = Query(...),
    selectedChoice: str = Query(...),
    userName: str = Query(...),
    allChoices: List[str] = Query(...),
):
    """ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒì— ëŒ€í•œ í”¼ë“œë°± ìŠ¤íŠ¸ë¦¬ë°."""
    
    async def event_generator():
        try:
            client = get_gemini_client()
            
            prompt = get_feedback_prompt(
                user_name=userName,
                scenario_title=scenarioTitle,
                scenario_description=scenarioDescription,
                all_choices=allChoices,
                selected_choice=selectedChoice,
            )
            
            full_response = ""
            feedback_text = ""
            questions_buffer = ""
            separator_found = False
            separator = "%%%QUESTIONS%%%"
            
            async for chunk in client.generate_content_stream(
                contents=prompt,
                config={"thinking_config": {"thinking_budget": 0}}
            ):
                if chunk.text:
                    chunk_text = chunk.text
                    full_response += chunk_text
                    
                    if separator_found:
                        questions_buffer += chunk_text
                    else:
                        if separator in chunk_text:
                            separator_found = True
                            parts = chunk_text.split(separator)
                            feedback_text += parts[0]
                            if len(parts) > 1:
                                questions_buffer += parts[1]
                            yield format_sse("feedback_chunk", {"text": parts[0]})
                        else:
                            feedback_text += chunk_text
                            yield format_sse("feedback_chunk", {"text": chunk_text})
            
            # í›„ì† ì§ˆë¬¸ íŒŒì‹±
            questions = []
            if questions_buffer:
                questions = [q.strip() for q in questions_buffer.strip().split('\n') if q.strip()]
            
            yield format_sse("questions", {"questions": questions})
            yield format_sse("result", {"text": feedback_text, "questions": questions})
            
        except Exception as e:
            logger.error(f"Feedback stream error: {e}")
            yield format_sse("error", {"message": str(e)})
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )


# ============================================
# í›„ì† ì§ˆë¬¸ ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
# ============================================

@router.get("/followup/stream")
async def followup_stream(
    sessionId: str = Query(...),
    scenarioId: str = Query(...),
    scenarioTitle: str = Query(...),
    scenarioDescription: str = Query(...),
    originalFeedback: str = Query(...),
    question: str = Query(...),
    userName: str = Query(...),
):
    """í›„ì† ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°."""
    
    async def event_generator():
        try:
            client = get_gemini_client()
            
            prompt = get_followup_prompt(
                user_name=userName,
                scenario_title=scenarioTitle,
                scenario_description=scenarioDescription,
                original_feedback=originalFeedback,
                question=question,
            )
            
            full_response = ""
            
            async for chunk in client.generate_content_stream(
                contents=prompt,
                config={"thinking_config": {"thinking_budget": 0}}
            ):
                if chunk.text:
                    full_response += chunk.text
                    yield format_sse("chunk", {"text": chunk.text})
            
            yield format_sse("result", {"text": full_response})
            
        except Exception as e:
            logger.error(f"Follow-up stream error: {e}")
            yield format_sse("error", {"message": str(e)})
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )


# ============================================
# ì§„í–‰ë„ ê´€ë¦¬ (Supabase ì˜ì†í™”)
# ============================================

@router.post("/progress")
async def save_progress(request: SaveProgressRequest):
    """ì‹œë‚˜ë¦¬ì˜¤ ì™„ë£Œ ì§„í–‰ë„ ì €ì¥ (Supabaseì— ì˜ì†í™”)."""
    repo = get_onboarding_repository()

    try:
        await repo.save_progress(
            session_id=request.sessionId,
            scenario_id=request.scenarioId,
            choice_id=request.choiceId,
            feedback_rating=request.feedbackRating,
        )
        logger.info(f"Saved progress for session {request.sessionId}: scenario {request.scenarioId}")
        return {"success": True}
    except Exception as e:
        logger.error(f"Failed to save progress: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/progress/{sessionId}")
async def get_progress(sessionId: str):
    """ì§„í–‰ë„ ì¡°íšŒ (Supabaseì—ì„œ ì¡°íšŒ)."""
    repo = get_onboarding_repository()

    try:
        summary = await repo.get_progress_summary(sessionId, total_scenarios=12)
        return {
            "userId": summary.user_id,
            "userName": summary.user_name,
            "completedScenarios": [
                {
                    "scenarioId": p.scenario_id,
                    "choiceId": p.choice_id,
                    "feedbackRating": p.feedback_rating,
                    "completedAt": p.completed_at.isoformat() if p.completed_at else None,
                }
                for p in summary.completed_scenarios
            ],
            "totalScenarios": summary.total_scenarios,
            "completionRate": summary.completion_rate,
        }
    except Exception as e:
        logger.error(f"Failed to get progress: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/progress")
async def get_all_progress():
    """ëª¨ë“  ì„¸ì…˜ì˜ ì§„í–‰ë„ ìš”ì•½ ì¡°íšŒ (ê´€ë¦¬ììš©)."""
    repo = get_onboarding_repository()

    try:
        summaries = await repo.get_all_sessions_summary()
        return {"sessions": summaries}
    except Exception as e:
        logger.error(f"Failed to get all progress: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ë¬¸ì„œ ì—…ë¡œë“œ (ì¸ìˆ˜ì¸ê³„/í”„ë¡œì„¸ìŠ¤ ë¬¸ì„œ)
# ============================================

@router.post("/documents")
async def upload_onboarding_document(
    file: UploadFile = File(...),
    metadata: Optional[str] = Form(None),
):
    """ì˜¨ë³´ë”©/ì¸ìˆ˜ì¸ê³„ ë¬¸ì„œ ì—…ë¡œë“œ."""
    if not STORE_HANDOVER:
        raise HTTPException(
            status_code=500,
            detail="Onboarding store not configured"
        )
    
    try:
        parsed_metadata = []
        if metadata:
            parsed_metadata = json.loads(metadata)
        
        file_content = await file.read()
        result = await upload_document_to_store(
            store_name=STORE_HANDOVER,
            file_name=file.filename or "document.txt",
            file_content=file_content,
            metadata=parsed_metadata,
        )
        
        logger.info(f"Uploaded document: {result.get('displayName')}")
        return result
        
    except Exception as e:
        logger.error(f"Document upload failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/documents")
async def list_onboarding_documents(
    category: Optional[str] = None,
):
    """ì—…ë¡œë“œëœ ì˜¨ë³´ë”© ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ."""
    if not STORE_HANDOVER:
        raise HTTPException(
            status_code=500,
            detail="Onboarding store not configured"
        )
    
    try:
        result = await get_store_documents(STORE_HANDOVER)
        documents = result.get("documents", [])
        
        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        if category:
            documents = [
                doc for doc in documents
                if any(
                    m.get("key") == "category" and m.get("stringValue") == category
                    for m in (doc.get("customMetadata") or [])
                )
            ]
        
        return documents
        
    except Exception as e:
        logger.error(f"Document list failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/documents/{document_name:path}")
async def delete_onboarding_document(document_name: str):
    """ì˜¨ë³´ë”© ë¬¸ì„œ ì‚­ì œ."""
    from app.services.gemini_file_search import delete_document
    
    try:
        await delete_document(document_name)
        logger.info(f"Deleted document: {document_name}")
        return {"success": True, "deleted": document_name}
        
    except Exception as e:
        logger.error(f"Document delete failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))
